{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shlokagarwal/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/shlokagarwal/Desktop/Computer Vision /Novel_NeRF/src/frame_manager.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shlokagarwal/Desktop/Computer%20Vision%20/Novel_NeRF/src/frame_manager.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shlokagarwal/Desktop/Computer%20Vision%20/Novel_NeRF/src/frame_manager.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shlokagarwal/Desktop/Computer%20Vision%20/Novel_NeRF/src/frame_manager.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimageio\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shlokagarwal/Desktop/Computer%20Vision%20/Novel_NeRF/src/frame_manager.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Make sure to switch runtime to the GPU\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shlokagarwal/Desktop/Computer%20Vision%20/Novel_NeRF/src/frame_manager.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import imageio\n",
    "# Make sure to switch runtime to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3026848341.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    class Frame:\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Write a class to read in the image frame and store all the data related to it \n",
    "class FrameManager:\n",
    "    def __init__(self):\n",
    "        self.test_frames = []\n",
    "        self.train_frames = []\n",
    "        self.val_frames = []\n",
    "        self.cam_angle = 0\n",
    "        self.f = None\n",
    "        self.H = None\n",
    "        self.W = None\n",
    "    \n",
    "    def read_frames(self, path):\n",
    "        cfgs = ['transforms_test.json', 'transforms_train.json', 'transforms_val.json']\n",
    "        data_cfg = {}\n",
    "        for i, cfg in enumerate(cfgs):\n",
    "            with open(os.path.join(path, cfg)) as json_file:\n",
    "                data_cfg[i] = json.load(json_file)\n",
    "        \n",
    "        for i in range(3):\n",
    "            data = data_cfg[i]\n",
    "            frms = []\n",
    "            for frame in data[\"frames\"]:\n",
    "                img_file = os.path.join(basedir, frame['file_path'] + '.png')\n",
    "                self.cam_angle = data_cfg[0]['camera_angle_x']\n",
    "                img = imageio.imread(img_file)\n",
    "                self.H, self.W = img.shape[0], img.shape[1]                  \n",
    "                '''It's basic geometry: you have a right angle triangle, with half the FOV as one of the angles (a), and half your image size as the opposite side (A). To calculate the focal length F, use tan(a) = A/F,\n",
    "which gives F = A/tan(a)'''\n",
    "                self.f = (0.5 * self.W)/(np.tan(0.5 * self.cam_angle))\n",
    "                new_frame = Frame(img, np.array(frame['transform_matrix'], self.f))\n",
    "                frms.append(new_frame)\n",
    "            if i == 0:\n",
    "                self.test_frames = frms\n",
    "            elif i == 1:\n",
    "                self.train_frames = frms\n",
    "            else:\n",
    "                self.val_frames = frms\n",
    "\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, image, pose, f):\n",
    "        self.img = image\n",
    "        self.pose = pose\n",
    "        self.H, self.W = image.shape[0], image.shape[1]\n",
    "        self.f = f\n",
    "        self.samples = None\n",
    "        self.rays_o = None\n",
    "        self.rays_d = None\n",
    "        self.depth_values = None\n",
    "\n",
    "    def copy_to_device(self, device):\n",
    "        self.img = torch.from_numpy(self.img).to(device)\n",
    "        self.pose = torch.from_numpy(self.pose).to(device)\n",
    "    # function to get the rays from the image through every pixel of the Camera (Using Pytorch) on GPU\n",
    "    # Assuming a pinhole camera model\n",
    "    def get_rays(self, device):\n",
    "        self.copy_to_device(device)\n",
    "\n",
    "        i, j = torch.meshgrid(torch.arange(self.H).to(device), torch.arange(self.W).to(device), indexing='ij')\n",
    "        i, j = i.transpose(1, 0), j.transpose(1, 0)\n",
    "        dirs = torch.stack([(i-self.W*0.5)/self.f, -(j-self.H*0.5)/self.f, -torch.ones_like(i)], -1)\n",
    "\n",
    "        rays_d = torch.sum(dirs[..., None, :] * self.pose[:3, :3], -1)\n",
    "        rays_o = torch.broadcast_to(self.pose[:3, -1], rays_d.shape)\n",
    "        self.rays_o = rays_o\n",
    "        self.rays_d = rays_d\n",
    "        \n",
    "        return rays_o, rays_d\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of frames and samples all the rays for the frames uniformly and returns the rays and the depth values\n",
    "# could make it a method of the FrameManager class\n",
    "def sample_frame(frames, num_samples, near, far, dev = 'cuda:0'):\n",
    "    \n",
    "    sample_space = torch.linspace(0., 1., num_samples, device=dev)\n",
    "    depth = near*(1.-sample_space) + far*sample_space\n",
    "    mid_depth = (depth[1:] + depth[:-1])/2\n",
    "    rand_sampling = torch.rand([num_samples], device=dev)\n",
    "    upper_sample = torch.cat([mid_depth, depth[-1:]], dim=-1)\n",
    "    lower_sample = torch.cat([depth[:1], mid_depth], dim=-1)\n",
    "    depth_value = lower_sample + rand_sampling * (upper_sample - lower_sample)\n",
    "    depth_value = depth_value.expand(list(frames.rays_o.shape[:-1]) +[num_samples])\n",
    "    #pts are the points on the ray in the format (width, height, n_samples, 3)\n",
    "    pts = frames.rays_o[..., None, :] + frames.rays_d[..., None, :] * depth_value[..., None]\n",
    "    frames.samples = pts\n",
    "    frames.depth_values = depth_value\n",
    "    return pts, depth_value\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
